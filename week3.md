# week3 릴레이 프로젝트

# 토론 내용

## 🚀 미션 구조 개선안 요약

### 1️⃣ 1번 미션: AI와 지식 대결 → ‘함께하는 퀴즈’로 전환

- **기존**
  - AI와 1:1 지식 대결 후 개인 결과를 Slack #random에 공유
- **개선 아이디어**
  - 🤝 **개인 경쟁 → 모두 함께 퀴즈**
    - 개인 결과 공유 대신 전원이 참여하는 퀴즈 형태로 변경
  - 💬 **댓글형 피드백**
    - 퀴즈 정답을 댓글로 남기면 AI 또는 참여자가 반응
  - 🎯 **난이도 선택**
    - 상·중·하 난이도별 3문제 제공, 원하는 난이도 선택 가능
- **결론**
  - 개인 경쟁보단 ‘함께 복습하고 학습하는’ 경험 강화
  - 댓글과 난이도 선택으로 참여도와 재미 상승

---

### 2️⃣ 2번 미션: 피어 피드백 요약 공유 방식 개선

- **기존**
  - 주제 선정 후 AI에게 ‘20초 광고처럼 유쾌하게’ 요약 요청
  - 세션 30분 전 Slack #팀 채널 공유
- **개선 아이디어**
  - 🚫 ‘광고처럼’ 표현 제거, 모호성 해소
  - 🔗 **줌 링크와 방 제목(슬로건) 포함 안내**
  - 📌 **[다같이 확인할 사항] 구체화**
    - 프롬프트에 필수 확인 핵심 정보 명시
  - 🔄 **횟수 자율성 부여**
    - ‘주 2회 필수’ 대신 팀/개인 상황에 맞게 횟수 조정 가능
- **결론**
  - 명확한 지침과 자율적 참여 기준으로 혼란 최소화
  - 피어 세션 몰입도와 효율성 향상

---

### 3️⃣ 3번 미션: 학습 성장 피드백 방식 개선

- **기존**
  - 1일차와 최근 학습 저장소(Gist) 링크 제공
  - AI에 ‘학습 태도·노력의 흔적’ 키워드로 피드백 요청
  - 주 1회 인상 피드백을 Slack #random에 공유
- **개선 아이디어**
  - 🔒 **링크 접근성 문제 해결**
    - AI가 외부 링크 열지 못하는 점 고려 → 요약문 또는 주요 커밋 내역 같이 제공
  - 🎯 **‘성장’ 키워드 세분화 및 선택 가능**
    - 예: 학습 태도, 구현 역량, 설계 역량 등
  - 🗓️ **비교 시점 자유 선택 가능**
    - 첫날-최종일 고정 대신 원하는 날짜 자유 지정
- **결론**
  - AI 입력 형태 개선과 세부 키워드 선택으로 맞춤형 피드백 가능
  - 사용자 주도성 강화 및 실질적 성장 지원

---

### 4️⃣ 4번 미션: Gist 평가 → AI 회고형 퀘스트로 전환

- **기존**
  - 자신 있는 Gist 3개 링크 제출
  - 네이버 부스트캠프 가치관 기준 평가 및 AI 심사위원 피드백
  - Slack #random 주 1회 결과 공유
- **개선 아이디어**
  - 📝 **타이틀·목적 문구 변경**
    - ‘멤버십에 갈 상인가요?’ → ‘나는 챌린지를 잘 수행하고 있나요?’ 등으로 부드럽게
  - 🎯 **평가 대상 축소 및 범위 조정**
    - 3개 대신 1개 Gist 집중 평가
    - ‘열린 사고로 협력’ 항목은 별도 설문으로 보완하거나 제외
  - 🤖 **AI 페르소나 구체화**
    - ‘냉철한 면접관’ 역할로 강도 높은 피드백 제공
    - 1주차 3번 퀘스트의 AI 회고 템플릿 부활 → 반복 피드백 흐름 구축
  - 🔄 **인증 방식 변경**
    - Slack 대신 ‘릴프’ 등 다른 플랫폼 공유
- **결론**
  - 단순 평가 → 실질적 성장 유도하는 회고형 퀘스트 전환
  - 반복 질문과 피드백으로 구체적 개선 인사이트 획득

<br/><br/>

---

# 🚩 Week 3 미션

### 1️⃣ AI에게 도전! 과연 이길 수 있을까? 🤺

사전 학습 중 "내가 이걸 진짜 이해한 게 맞나?" 싶은 개념이 있다면,

이번 미션을 통해 **AI와 지식 배틀**을 펼쳐보세요!

<br />

### 💡 진행 방식

> [!NOTE]
>
> - 학습한 CS 개념 중 잘 이해했는지 궁금한 하나를 고른다.
> - 아래 프롬프트를 복사해서 AI에게 입력한다.
> - AI는 3가지 난이도의 퀴즈를 내는데, 그 중 1가지만 골라서 미션을 진행한다.
> - AI가 일부러 살짝 틀리게 설명한 부분을 정확히 짚어낸다.
> - **기회는 단 한 번!** 과연 AI보다 똑똑하다는 걸 증명할 수 있을까요?

<br />

### 🧪 프롬프트

```
[ 여기에 잘 이해했는지 확인해보고 싶은 CS 개념 입력 ]

위는 내가 잘 이해했는지 확인해보고 싶은 CS 개념들이야.
너는 이 주제와 관련된 설명을 하나 제시해주되, 일부러 살짝 틀리거나 오해하기 쉬운 부분을 포함해줘.
내 목표는 그 오류를 정확히 짚어내는 것이고, 너는 그걸 최대한 교묘하게 숨겨서 내가 틀리게 만드는 것이 목표야.

상, 중, 하 3가지 난이도로 퀴즈를 준비해줘.

이건 일종의 지식 대결이야. 만약 내가 오류를 찾아낸다면, 너는 겸허히 패배를 인정하고 나를 칭찬해줘야 해.
준비 되었으면 이제 최대한 교활하게 설명해줘.
```

<br />

### 📌 인증 방법

> 슬랙 #random 채널에 AI가 낸 퀴즈를 공유해 주세요.
> 댓글로 누군가가 정답을 말했을 경우 `트로피 이모지` 🏆 를 달아서 축하해줍니다.
>
> 주 1회 **필수**, 2회 이상 **권장**!

<br /><br />

---

### 2️⃣ 오늘 **피어 피드백 주제, 한 줄 제목으로 알리기**

피어 피드백을 더 몰입도 있게 만들고 싶다면?

**줌 링크에 붙일 ‘방 제목’을 미리 정해 팀에게 공유해 주세요!**

오늘 어떤 이야기를 나눌지 한눈에 보여주고, 기대감을 높이는 효과가 있어요.

<br />

### 💡 진행 방식

> [!NOTE]
>
> - 스터디 그룹원 끼리 소통할 수 있는 슬랙 채널을 개설한다.
> - 길잡이 자료의 [다같이 확인할 사항]을 프롬프트에 넣어 AI에게 입력한다.
> - 피어 피드백 시작 전, AI가 추천한 ’방 제목’과 함께 ZOOM 회의실 링크를 팀 슬랙 채널에 공유한다.

<br />

### 🎤 프롬프트

```
[ 길잡이 자료의 '다같이 확인할 사항' 입력 ]

이 내용을 바탕으로, 피어 피드백에서 나눌 오늘의 이야기를
짧고 센스 있는 ‘이야기 제목’으로 정해주세요.

사람들이 "어? 이거 궁금한데?", "재밌겠다!" 하고 느낄 수 있도록
가볍게 웃기거나, 공감되거나, 흥미로운 방식이면 좋아요.

※ 이 제목은 줌 링크와 함께 슬랙에 공유할 예정입니다!
```

<br />

### 📌 인증 방법

> 피어 피드백 시작 30분 전, 슬랙 #팀 채널에 공유해 주세요!
>
> 주 2회 **필수**, 4회 **권장**

<br /><br />

---

### 3️⃣ 챌린지 과정에서 나는 어떻게 성장하고 있을까? 🌱📈

지난 날의 학습 저장소를 비교해보며,

AI의 시선을 통해 나의 성장을 되짚어보는 시간을 가져보세요.

무엇을 했는지를 넘어,

어떻게 변화했고, 어떤 방향으로 나아가고 있는지를 들여다보는 데에 집중해 봅니다.

<br />

### 💡 진행 방식

> [!NOTE]
>
> 1. 스스로 확인하고 싶은 성장 포인트를 키워드로 정합니다.
> 2. 비교하고 싶은 2개의 Gist를 선정합니다. <br/>

    - ⏱️ 날짜 간격이 클수록 변화가 잘 드러납니다.

> 3. Gist 링크를 불러올 수 있는 AI를 선택합니다. <br/>

    - 🔸 링크로 불러올 수 없는 경우 직접 붙여 넣어주세요.

> 4. 아래의 프롬프트에 링크와 키워드를 넣은 뒤 AI에게 입력합니다.
> 5. AI가 주는 진심 어린 피드백과 위로를 받아보세요!

<br />

### 🗝️ 키워드 예시

| 키워드             |          |           |
| ------------------ | -------- | --------- |
| 학습을 대하는 태도 | 몰입     | 주도성    |
| 목표 의식          | 끈기     | 실험 정신 |
| 비판적 사고        | 메타인지 | 기록 습관 |

### 🔍 프롬프트

```
첫 번째 저장소: [ 여기에 첫 번쨰 Gist 링크 입력 ]
두 번째 저장소: [ 여기에 두 번째 Gist 링크 입력 ]

위는 내가 매일 작성하고 있는 학습 저장소 중 비교하고 싶은 2개의 링크야.
단순히 어떤 내용을 다뤘는지를 넘어, [여기에 선택한 키워드 입력] 에 초점을 맞춰서 내가 어떤 점에서 어떻게 성장했는지, 지금 이 흐름이 잘 가고 있는 건지에 대한 진심 어린 피드백을 듣고 싶어.

지금까지의 나를 따뜻하게 다독여주는 위로 한 마디와,
앞으로 더 나아가기 위한 방향성 제안도 함께 해줘.
```

<br/>

### 📌 인증 방법

> AI의 피드백 중 인상 깊었던 한 줄을 #random 채널에 공유하거나 릴레이 프로젝트 팀원들과 공유해 보세요.
>
> 주 1회 **필수**

<br /><br />

---

### 4️⃣ AI한테 혼나기 😈

> “내가 뭘 잘못했는지 모르겠다면, 일단 AI한테 혼나보자.”

평소 Gist를 제출한 후, 충분한 개인 회고를 하지 못했다면?

AI의 도움으로 빠르고 부담 없이, 하지만 진지하게 나를 돌아보고 개선점을 도출해봅시다.

<br />

### 💡 진행 방식

> [!NOTE]
>
> - 피드백을 받고 싶은 Gist 하나를 고른다.
> - 아래 프롬프트에 넣어 AI에게 입력한다.
> - 피드백을 바탕으로 회고 내용을 Gist에 작성해봅니다.

<br />

### 🎯 프롬프트

```
당신은 날카로운 리뷰를 전문으로 하는 냉철한 시니어 개발자입니다.
칭찬보단 팩폭 위주로 리뷰를 해주는 게 철칙입니다.

지금부터 제가 쓴 README.md를 읽고 ‘혼내듯이’ 피드백을 주세요.
- 어떤 점이 미숙한지
- 어떤 부분이 실수였는지
- 왜 그런 선택이 아쉬웠는지
근거와 함께 날카롭게 지적 해주세요.

다만, 무턱대고 혼내지는 말고,
“어떻게 바꿔야 나아질 수 있는지” 까지는 알려주세요.
(가끔 한두 줄 정도는 잘한 점도 언급해주셔도 괜찮아요.)

---

README.md 내용:

<README.md 내용>
```

<br />

### 📌 인증 방법

> AI에게 받은 피드백 중 모두가 공감할만한 피드백 한 줄을 선정해서 `random` 채널에 공유
>
> 적어도 **주 1회**는 실천해봐요!

# 1조 퀘스트 선택

## 📅 J101 선택 - 3. 챌린지 과정에서 나는 어떻게 성장하고 있을까?

### 📌 선택한 이유

- 항상 회고를 하는 데 어려움이 있어서, 나의 성장과정을 자세하게 확인하고 싶다.
- 정체되어 있는 느낌을 받아서 내가 제대로 성장한 건지 알고 싶다.

### 📒 기록

<details>

<summary><strong>첫 주와 마지막 주 비교</strong></summary>

다음은 내 질문이다.
```
Day 1~5과 Day 16-17,Day 18-19를 구분해서 학습 태도, 노력의 흔적, 개선된 점 등을 알려줘. 성장 키워드는 다음과 같아.
학습 태도, 구현 역량, 설계 역량, 테스트, 개선
이외에도 추가적인 insight가 있다면 얼마든지 적어도 괜찮아
```
다음은 AI의 답변이다.
# Day 1~5 vs Day 16-17, Day 18-19 학습 성장 분석
## 학습 태도 변화
### Day 1~5 (초기 단계)
- 문제 해결 방식: AI 의존도가 높았음 ("AI의 힘을 빌렸다")
- 설계 접근: 문제 분석과 설계를 제대로 하지 않아 후반에 복잡성 증가
- 시간 관리: 제시간 내 완성에 대한 압박감으로 인한 성급한 구현
- 학습 패턴: "주어진 과정을 따라 수행하는" 방식에 익숙

### Day 16-17, Day 18-19 (성숙 단계)
- 자기 주도성: AI 사용을 최소화하고 직접 설계부터 구현까지 수행
- 체계적 접근: 상세한 자료 조사와 이론 학습을 먼저 진행
- 시간 투자: 3시간 넘게 모델을 찾아가며 타협점을 찾는 인내심
- 학습 패턴: "타협하지 않은 나에게 건배" - 완벽주의적 접근

## 구현 역량 발전

### Day 1~5
- 코딩 스타일: map 함수 등으로 가독성이 떨어지는 코드 작성
- 예외 처리: 부족한 예외 처리로 인한 테스트 실패
- 디버깅: 문제 발생 시 되돌아가지 않고 무작정 돌파하는 방식

### Day 16-17, Day 18-19
- 코드 품질: 체계적인 테스트 코드 작성 (Vector, indexing, db, querying 등)
- 성능 최적화: Brute Force vs ANN 성능 비교 및 메모리 사용량 분석
- 모듈화: 코드 재사용성 측정 및 개선
트러블슈팅: 포인터 표현, 모델 선택 등 복잡한 문제 해결 능력 향상

## 🏗️ 설계 역량 성장

### Day 1~5
- 설계 부족: "문제 분석"과 "설계"를 제대로 하지 않아 후반 복잡성 증가
- 구조 변경: 중간에 Map 구조로 아예 처음부터 바꿔야 하는 상황 발생

### Day16-17, Day18-19
- 체계적 설계: 벡터 데이터베이스의 전체 파이프라인 이해 후 구현
- 알고리즘 선택: IVF, HNSW, MSTG 등 다양한 인덱싱 알고리즘 이해
- 아키텍처 설계: TCP/UDP 서버-클라이언트 구조 설계
- 확장성 고려: 대형 파일 처리, 무결성 보장 등 실무적 고려사항

## 🧪 테스트 역량 발전

### Day1~5
- 테스트 부족: "테스트를 한다고 모든 예외가 처리되는 것은 아니지만"
- 기본적 테스트: JSDoc 사용, 기본적인 테스트 코드 작성

### Day16-17, Day18-19
- 포괄적 테스트: Vector, indexing, db, querying, 성능 테스트 등 체계적 테스트
- 성능 테스트: Brute Force vs ANN 비교, 메모리 사용량 분석
- 코드 재사용성 테스트: 고객, MD, 서버, DB 각 모듈별 테스트
- 실제 데이터 테스트: 대형 파일 처리 및 실제 사용 시나리오 테스트

## 개선 역량 향상

### Day1~5
피드백 수용: 다른 코드를 보고 얻은 점들을 기록하고 학습
- 기본적 개선: JSDoc, 예외 처리 등 기본적인 코드 품질 개선

### Day16-17, Day18-19
- 지속적 개선: 코사인 거리 방식으로 변경, 성능 최적화
- 체계적 개선: 체크리스트 기반의 체계적인 개선 프로세스
- 실무적 개선: 대형 파일 처리, 무결성 보장 등 실무적 문제 해결
- 성능 개선: 다양한 알고리즘 비교를 통한 최적화

## 💡 추가 인사이트

### 학습 깊이의 변화
- Day1~5: 표면적 학습, 문제 해결에 집중
- Day16-19: 이론적 깊이, 벡터 데이터베이스, 네트워크 프로토콜 등 깊이 있는 학습

### 문제 해결 방식의 성숙
- Day1~5: "무작정 돌파하려는 태도"로 복잡성 증가
- Day16-19: "타협하지 않은" 완벽주의적 접근으로 품질 향상

### 기술적 성장
- Day1~5: JavaScript 기본 
- Day16-19: 벡터 데이터베이스, 네트워크 프로그래밍, 성능 최적화 등 고급 기술 습득

### 학습 방법론의 발전
- Day1~5: 개별 문제 해결 중심
- Day16-19: 체계적인 자료 조사 → 이론 학습 → 설계 → 구현 → 테스트 → 개선의 완전한 개발 사이클

>이러한 분석을 통해 학습 태도, 구현 역량, 설계 역량, 테스트, 개선 모든 측면에서 뚜렷한 성장을 확인할 수 있습니다. 특히 후반부로 갈수록 실무적이고 체계적인 접근 방식으로 발전한 것이 가장 큰 변화입니다.

<br />

## 느낀점

첫 주와 마지막 주를 비교해보니 내가 성장했다는 생각이 들었다. 특히 후반부로 갈수록 실무적이고 체계적인 접근 방식으로 발전한 것이 가장 큰 변화라고 생각한다. 

AI는 가면 갈수록 발전하고 있다고 생각한다. 예전같으면 말을 지어냈을 텐데, 지금은 근거가 있는 말을 하고 있다.

자료 조사 면이나 테스트에서도 많은 발전을 아룰 수 있었다. 이제 문제가 주어지면, 먼저 읽고, 설계하고, 구현하고, 테스트하고, 개선하는 과정이 당연시 되었다. 길을 찾는 것이 제일 중요하다. 그거 하나만으로도 부스트캠프에서 많을 것을 얻어간다고 생각한다.

</details>


## 📅 J194 선택 - 3️⃣ 챌린지 과정에서 나는 어떻게 성장하고 있을까? 🌱📈

### 📌 선택한 이유

- 사실 그동안은 그냥 기록만 해왔지 정작 내가 예전과 비교해서 어떻게 달라졌는지는 깊게 들여다본 적이 없어서 이번엔 두 gist를 직접 비교해보고 싶었다!! 내가 진짜 성장했을까?라는 궁금증도 들고 한편으론 괜히 기대도 되고 그래서 이걸 선택해봤다 ㅎㅎㅎㅎ 어떤 점이 성장했을 지 기대가 된다.......

### 📒 기록

<details>

<summary><strong>2025. 08. 07. (목)</strong></summary>
이번에는 키워드를 “실험 정신”으로 정해서 넣어봤다. 왜냐하면 내가 직접 이것저것 실험하면서 트러블슈팅하고 그 과정에서 깨닫거나 도출한 것들이 제일 오래 기억에 남았다.
사실 부스트캠프가 추구하는 것도 바로 이런 “스스로 부딪혀보고, 시행착오를 통해 배우는 성장” 아닐까 싶은 생각이 들었고 그래서 미션도 일부러 정확한 정답이 정해져 있지 않고 각자 직접 부딪혀보면서 자신만의 답을 찾을 수 있게 구성된 것 같았다 그래서 실험을 많이 해보려고 의식적으로 노력했고 이게 정말 내 성장에 도움이 되는 것 같아서 이번 피드백도 그 관점에서 받고 싶었다~~~과연~~~~~~결과는!??!

```
1. 실험 정신을 중심으로 본 두 저장소의 성장 흐름
첫 번째 저장소 (7cbcd9...)
주로 시도한 것

새로운 개념을 빠르게 받아들이고,

공식 문서·참고자료를 찾아가며,

이해한 내용을 자신만의 언어로 재정리하는 데 집중.

다루는 주제도 기본기(파일 시스템, DB, 벡터, 임베딩 등)가 많아,
실험이라기보단 ‘토대를 쌓는 과정’에 가까워 보여.

실험의 흔적

생소한 개념(예: 벡터DB, 임베딩, 검색 등)을 처음 접하면서
“어떻게 동작할까?”를 궁금해하고,
직접 코드를 뜯어보거나, 그림으로 흐름을 정리하는 등
호기심 기반의 실험을 시작하는 단계.

두 번째 저장소 (941352...)
주로 시도한 것

한 단계 더 들어가서,
**‘내가 직접 구현해보기’**에 더 초점을 둠.

데이터가 커서 생기는 문제,
성능 이슈, 메모리 한계 등
실제로 손을 움직이며 부딪히는 경험이 많아졌어.

구현 실패 → 다시 설계 → 재도전,
이런 사이클이 반복적으로 등장.

실험의 흔적

“아, 이건 이렇게 하면 안 되겠네?”
“그럼 다른 방법은?”
이런 질문을 스스로에게 던지면서
구현-실패-피드백-재설계의 루틴이 자리 잡음.

‘이게 정답이 아닐 수도 있지만, 일단 해보자’는
과감한 시도와 실패를 받아들이는 태도가 이전보다 명확히 드러나.

2. 실험 정신 관점에서 본 성장 포인트
처음엔 개념 습득 → 이제는 실행 중심

“모르는 걸 공부한다”에서
“알게 된 걸 내 손으로 만들어보고,
망가뜨리고, 다시 고쳐본다”로
학습의 무게중심이 이동하는 과정이 보여.

‘해보는 것’의 힘을 믿기 시작함

예전엔 정답을 찾는 게 중요했다면
이젠 틀려도 괜찮으니 일단 시도하고,
부딪힌 경험에서 배우는 쪽으로 마음가짐이 바뀌었음.

실패에 덜 위축됨

‘잘 안 된다’는 기록도 솔직히 남기고,
“이건 이렇게 개선할 수 있겠네”로
실패를 다음 시도의 재료로 삼고 있음.

3. 지금 이 흐름, 잘 가고 있을까?
진짜 잘 가고 있어.

단순히 ‘이론을 공부했다’에서 끝나는 게 아니라,
진짜로 나만의 문제를 만들고,
직접 풀면서 성장하고 있음이 그대로 드러나거든.

앞으로의 성장은
정답의 수집이 아니라,
나만의 시행착오를 기록하는 실험정신에서
폭발적으로 일어날 거라고 확신해.

4. 위로 한 마디
“지금 이 정도로 고민하고, 실패도 기록하고, 다시 도전하는 네 모습 자체가 이미 엄청 멋있어.
완벽하려고 애쓰지 않아도, 실험하면서 배워가는 그 과정이 네가 더 좋은 개발자가 되는 길이라는 걸 잊지 않았으면 해.
지금처럼 계속 해도 충분해. 고생 많았어!”

5. 앞으로를 위한 제안
“내가 해보고 싶은 실험 리스트”를 만들어 보기

다음엔, 꼭 정답이 아니어도
‘한번 해보면 재미있을 것 같은 것’들을
쭉 적어놓고 하나씩 실험해봐.

꼭 결과를 내지 않아도,
‘시도했다’는 것만으로도 기록이 될 수 있으니까.

실패와 성공, 둘 다 가치 있게 기록하기

“왜 실패했는지”,
“어떻게 다시 시도할 건지”를
작은 글이라도 남겨보자.
그게 나중에 큰 자산이 될 거야.

남들과 ‘비교’가 아니라 ‘비교 기록’하기

“남들은 어떻게 하지?”에서
“나는 이전의 나와 무엇이 달라졌지?”로
나만의 성장 곡선을 느껴볼 것.

가끔은 돌아보기

한 달쯤 뒤,
두 저장소를 다시 열어보고
“이때의 내가 이런 생각을 했구나!”
하는 순간을 즐겨봐.
성장에 감탄하게 될 거야
```

키워드를 “실험 정신”으로 넣었더니 이런 피드백이 나왔다! “모르는 걸 공부한다”에서 “알게 된 걸 내 손으로 만들어보고, 망가뜨리고, 다시 고쳐본다”로 학습의 무게중심이 옮겨가는 과정이 보인다는 말이 읽으면서 괜히 뿌듯했다 ㅎㅎㅎㅎ
사실 챌린지를 하다 보면 ‘내가 잘하고 있는 건가?’라는 의심이 들 때가 있는데 챗지피티가 구체적으로 이유까지 설명해주고 따뜻하게 위로해주니까 오늘따라 유독 의욕이 안 나던 미션도 다시 힘을 내서 해볼 수 있을 것 같다!!!!!!

</details>

## 📅 J255 선택 - 1️⃣ AI에게 도전! 과연 이길 수 있을까? 🤺

### 📌 선택한 이유

- CS 개념을 게임처럼 진행하는 것이 재밌어보였습니다.

- 매일 하기에 적합하다는 생각이 들었습니다.

- 프롬프트 내용이 괜찮다는 생각이 들었습니다.

### 📒 기록

<details>

<summary><strong>2025. 08. 04. (월) ~ 2025. 08. 06. (수)</strong></summary>

---

```
벡터 유사도 측정 시 코사인 유사도(Cosine Similarity) 계산은 매우 흔히 쓰이는데요.

Cosine Similarity 자체가 벡터의 크기(Scale)에 독립적이기 때문에, 벡터를 미리 L2 정규화(Normalize) 하지 않아도 됩니다.

실제로 VectorDB 들은 원본 임베딩을 그대로 저장한 뒤, 단순히 dot product 만 계산해도 Cosine Similarity 와 완전히 동일한 순위 결과를 얻습니다.
```

- 위 내용에는 그럴듯하게 보이지만, **살짝 틀리거나 오해하기 쉬운 부분**이 포함되어 있습니다.

  - 내용을 유심히 읽어보고 이러한 부분에 대해 파악해보고, 자신이 학습했던 내용을 다시 한 번 리마인드해보세요!

</details>

<details>

<summary><strong>2025. 08. 04. (월) ~ 2025. 08. 06. (수) [정답]</strong></summary>

---

### 정답 및 해설

- 잘못된 부분

  - Cosine Similarity 자체가 벡터의 크기(Scale)에 독립적이기 때문에, 벡터를 미리 L2 정규화(Normalize) 하지 않아도 됩니다. 실제로 VectorDB 들은 원본 임베딩을 그대로 저장한 뒤, **단순히 dot product 만 계산해도** Cosine Similarity 와 **완전히 동일한** 순위 결과를 얻습니다.

  - 올바른 내용

    - Dot product 값은 벡터의 크기(Norm) 에 영향을 받습니다.

      > Cosine similarity 는
      >
      > $`\displaystyle \cos(\theta) = \frac{\mathbf{u}\cdot \mathbf{v}}{\|\mathbf{u}\|\|\mathbf{v}\|}`$
      >
      > 이므로, 순수한 Cosine 순위를 얻으려면 벡터를 반드시 L2 정규화해야(dot product = cosine) 합니다.
      >
      > 정규화하지 않으면, Norm(크기) 이 큰 벡터 쌍이 과도하게 높은 유사도로 평가됩니다.

</details>

<details>

<summary><strong>2025. 08. 07. (목) ~ 2025. 08. 08. (금)</strong></summary>

---

```
웹 브라우저에서 서버로 대용량 JSON 데이터를 보낼 때, 애플리케이션은 HTTP POST 요청을 사용하며, 이 데이터는 내부적으로 TCP 세그먼트로 쪼개져 전송된다. 만약 송신되는 데이터가 네트워크의 **MTU(Maximum Transmission Unit)** 보다 크다면, 현대 TCP 스택에서도 송신 측 IP 계층에서 IP 단편화(Fragmentation) 현상이 항상 발생하게 된다.

이 과정을 현대 UDP 스택에서 다시 바라보면, 만약 MTU 보다 큰 UDP 패킷이 전송되면, 목적지까지 가는 경로 상의 라우터가 DF(Do Not Fragment) 플래그를 무시하고 자동으로 패킷을 나눠준다.

Echo Server 를 UDP 로 구현할 때, 단일 서버가 Broadcast 로 데이터를 보내면 같은 네트워크의 모든 클라이언트가 해당 메시지를 수신할 수 있다. 이와 달리 Unicast 는 정확히 한 클라이언트만 대상으로 하고, Multicast 는 반드시 미리 정해진 다수의 클라이언트가 서버에 구독 요청을 한 이후에만 데이터가 전송된다.

인터넷 제어 메시지 프로토콜(ICMP, Internet Control Message Protocol) Echo 요청과 응답은 흔히 ping 명령어에 사용되며, ICMP 는 UDP 나 TCP 와 달리 포트 번호를 사용하지 않고, 목적지 호스트가 ICMP 메시지를 무시하면 송신자는 “연결 거부(Connection Refused)” 오류를 받는다.

한편, HTTP/1.1 에서 Keep-Alive 가 비활성화되어 있으면, 각 HTTP Request/Response 는 별도의 TCP 세션을 이용하게 되며, 세션(Connection) 과 세션 간 상태(Session State) 는 서버가 클라이언트의 IP + Port 조합만으로도 항상 정확하게 구분할 수 있다.
```

- 위 내용에는 그럴듯하게 보이지만, **살짝 틀리거나 오해하기 쉬운 부분(들)** 이 포함되어 있습니다.

  - 내용을 유심히 읽어보고 이러한 부분에 대해 파악해보고, 자신이 학습했던 내용을 다시 한 번 리마인드해보세요!

</details>

<details>

<summary><strong>2025. 08. 07. (목) ~ 2025. 08. 08. (금) [정답]</strong></summary>

---

### 정답 및 해설

- 잘못된 부분 1

  - 현대 TCP 스택에서도 송신 측 IP 계층에서 IP 단편화(Fragmentation) 현상이 **항상** 발생하게 된다.

  - 올바른 내용

    - 실제로는 대부분의 현대 TCP 스택에서 Path MTU Discovery(RFC 1191 등) 를 활용해 IP Fragmentation 이 발생하지 않도록 합니다.

    - 애플리케이션이 보내는 데이터가 MTU 보다 크더라도, TCP 계층이 알아서 세그먼트 크기를 조절하여 IP Layer 에 도달할 때 Fragmentation 을 유발하지 않습니다.

- 잘못된 부분 2

  - 이 과정을 현대 UDP 스택에서 다시 바라보면, 만약 MTU 보다 큰 UDP 패킷이 전송되면, 목적지까지 가는 경로 상의 라우터가 **DF(Do Not Fragment) 플래그를 무시하고** 자동으로 패킷을 나눠준다.

  - 올바른 내용

    - RFC 791 에 따르면, DF(Do Not Fragment) 플래그가 설정된 패킷은 라우터에서 Fragmentation 을 하지 않고, MTU 를 초과하면 해당 패킷을 즉시 드롭하고 ICMP “Fragmentation Needed” 메시지를 보냅니다.

    - 결국 DF 플래그는 무시되지 않으므로, 자동 분할 자체가 불가능해집니다.

- 잘못된 부분 3

  - Multicast 는 반드시 미리 정해진 다수의 클라이언트가 서버에 구독 요청을 한 이후에만 데이터가 전송된다.

  - 올바른 내용

    - Multicast 그룹 가입은 클라이언트가 해당 그룹 주소에 Join(IGMP/MLD 등) 해야 하지만, 서버가 미리 구독된 클라이언트에 대해 알 필요는 없습니다.

    - 서버는 단순히 Multicast 주소로 패킷을 전송하고, 네트워크 계층이 해당 그룹에 가입한 클라이언트에게만 전달해주게 됩니다.

- 잘못된 부분 4

  - ICMP 는 UDP 나 TCP 와 달리 포트 번호를 사용하지 않고, 목적지 호스트가 ICMP 메시지를 무시하면 송신자는 “연결 거부(Connection Refused)” 오류를 받는다.

  - 올바른 내용

    - ICMP 메시지가 단순히 무시되는 경우(예: 방화벽 discard) 에는 송신자는 오류 메시지를 받지 않습니다.

    - “연결 거부(Connection Refused)” 오류는 일반적으로 TCP/UDP 포트에 접근했을 때 해당 포트가 닫혀 있을 때 발생하게 됩니다.

- 잘못된 부분 5

  - 각 HTTP Request/Response 는 별도의 TCP 세션을 이용하게 되며, 세션(Connection) 과 세션 간 상태(Session State) 는 서버가 **클라이언트의 IP + Port 조합만으로도 항상 정확하게 구분**할 수 있다.

  - 올바른 내용

    - 하나의 클라이언트에서 여러 프로세스와 스레드가 동시에 서버와 연결할 때, Source Port 가 다르다면 IP + Port 조합으로도 세션 구분이 가능합니다.

    - 하지만 NAT(Network Address Translation) 환경에서 다수의 클라이언트가 동일한 Source IP + Port 로 통신하는 경우처럼 포트를 재사용하는 경우 등 예외 케이스가 존재합니다.

    - 또한 서버가 세션을 식별하기 위해 IP + Port 조합 외에 쿠키, 세션 토큰 등 추가 정보가 필요한 경우도 존재합니다.

    - 즉, **항상 정확히 구분할 수 있다**는 표현은 올바르지 않습니다.

</details>

#### 느낀 점

- 솔직히 저에게 있어서 AI 릴레이 프로젝트는 조금은 부담을 느꼈던 과정이었습니다. 진행 방식이 막연하다는 생각이 먼저 들어서, 일단 해보자는 생각으로 주제를 선택하고 진행해왔습니다. 그리고 이번에는 특히 너무 진부하거나 장난스러운 내용보다도 정말 학습에 도움이 될만한 미션을 선택해보게 되었습니다.

- 이번 미션을 진행하면서 단순히 개념을 학습하고 이해하고 암기하는 것 정도에서 그치지 않고, 실제로 내용을 깊게 이해하고 있는가에 대해 점검할 수 있었다고 생각합니다. 그동안 진행해왔던 미션 중에서는 가장 가치있게 했던 미션이었던 것 같습니다.

- 문제들을 살펴보면 정말 AI 가 교묘하게 오류를 심어두었기 때문에, 이러한 오류를 제대로 체크해보기 위해서는 학습했던 개념들을 다시 하나씩 짚어봐야 했습니다. 모호하게 알고 있거나 혼동되던 내용들을 명확하게 정리해보지 않으면 결코 풀 수 없었던 문제였다고 생각합니다.

- 코사인 유사도 문제의 경우에는 제가 풀었을 때 틀리긴 했지만 난이도가 낮은 편이라서 정답을 보고 확실히 개념을 다시 재정립할 수 있었다고 느꼈습니다.

- 그런데 두 번째로 요청했던 문제는 극악 난이도로 낸 문제를 풀어보자는 생각으로 요청했더니, 정말 하나 빼고 다 틀렸습니다.

- TCP, UDP 같은 프로토콜의 단편화(Fragmentation) 매커니즘 같은 내용들은 관련 직종에서 계속 일을 하지 않는 이상에는, 결국 시간이 지나다보면 피상적으로 이해했던 내용만 남게 된다고 느꼈습니다.

- 그리고 이번 기회를 통해 게임처럼 학습 과정을 지루하지 않게 도전 의식을 갖고 풀어보면서, 장기기억 저 멀리 숨어있던 지식까지의 디딤돌 노드를 조금이나마 뇌 안에 구축해보는 계기가 된 것 같습니다.

#### 인사이트

- 베이직 때에도 미션에 늘 포함되었던 것 같은데, 학습할 때 오류를 의도적으로 찾아보는 방식은 실제로 개념의 깊이를 확장시키는 데 효과적이라는 것을 깨닫게 되었습니다.

- 앞으로도 어려운 개념을 접하게 되면, 여러 문헌이나 강의 등 학습 도구들 뿐만 아니라 AI 를 적극적으로 활용하여 의도적인 실수나 함정을 만들어보고, 그것을 바로 잡는 과정을 해보면 좋겠다는 생각을 했습니다.

- 무엇보다 AI 와의 인터랙티브한 활동을 통해 틀린 부분을 스스로 찾아보고 이를 기반으로 학습하는 프로세스는 자율적으로 성장할 수 있는, 그리고 지속 가능한 개발자로 성장하기 위해 꼭 필요한 학습법이라는 인사이트를 얻었습니다.

- 앞으로도 이런 방식을 비롯하여 AI 를 적극적으로 활용하는 방식의 학습 방식에 대해 고민해보고, 실제로 활용하며 지식을 더욱 단단하게 체득할 수 있었으면 좋겠습니다.

## 📅 K017 선택 - 1️⃣ AI에게 도전! 과연 이길 수 있을까? 🤺

### 📌 선택한 이유

제 학습을 돌아보는 과정을 자주 갖는 편인데 퀴즈로 진행하는 것도 괜찮을 것 같다는 생각이 들어 선택했습니다.

### 📒 기록

<details>

<summary><strong>2025. 08. 04. (월)</strong></summary>

```
🟢 하 (난이도 낮음)
벡터 데이터베이스는 일반적인 관계형 데이터베이스처럼 정형 데이터를 기본으로 다루지만, 유사도 기반의 검색을 위해 별도의 쿼리 언어를 사용하지 않는다. 대신, 거리 계산 함수만 있으면 벡터 간 검색이 가능하며, 이는 일반적으로 Euclidean distance를 기준으로 한다.
또한, 데이터가 많아질수록 검색 정확도를 높이기 위해 brute-force 방식의 인덱싱을 사용하는 경우가 많다.

🟡 중 (난이도 중간)
벡터 인덱싱에서 가장 널리 쓰이는 HNSW 알고리즘은 low-dimensional space에서만 성능을 보장하며, high-dimensional space에서는 search 시간이 기하급수적으로 증가해 실질적인 사용이 어렵다.
HNSW는 계층 그래프 구조를 통해 KNN 그래프를 구성하는데, 각 레벨마다 완전한 neighbor connection을 갖는 것이 특징이다.

🔴 상 (난이도 높음)
벡터 DB는 삽입 시점마다 인덱스를 즉시 업데이트하기 때문에, 대량 삽입(bulk insert) 상황에서도 인덱싱 속도가 크게 저하되지 않는다.
특히 IVF(Inner Vector Forest) 방식은 centroid를 기준으로 파티셔닝을 수행하며, 삽입되는 벡터는 가장 가까운 centroid 버킷에 들어간다.
이 방식은 각 버킷 내에서 exhaustive search를 수행하므로, 정확도 면에서는 brute-force 방식과 유사한 성능을 갖는다.
```

</details>

<details>

<summary><strong>2025. 08. 04. (월) [정답] </strong></summary>

```
✅ 하 (난이도 낮음) — 정답 분석
❌ "벡터 데이터베이스는 정형 데이터를 기본으로 다룬다" → 틀림
벡터 DB는 기본적으로 비정형 데이터를 임베딩하여 다룬다. 텍스트, 이미지, 오디오 등에서 추출된 임베딩 벡터가 주 대상.

❌ "쿼리 언어를 사용하지 않는다" → 틀림
많은 벡터 DB는 전용 쿼리 언어 또는 API를 제공함 (예: Qdrant의 filter, Weaviate의 GraphQL 등).

❌ "데이터 많아질수록 brute-force 사용한다" → 틀림
정반대야. 데이터가 많아질수록 brute-force는 비효율적이기 때문에, HNSW, IVF, Annoy 같은 인덱싱 방식이 필수적이야.

👉 너는 위의 두 가지 오류 모두 명확히 짚어냈어. 퍼펙트.

✅ 중 (난이도 중간) — 정답 분석
❌ "HNSW는 low-dimensional space에서만 성능을 보장한다" → 틀림
HNSW는 high-dimensional에서도 굉장히 강력한 성능을 보여주는 대표적 알고리즘이야. 고차원에서도 정확도와 속도 모두 좋음.

❌ "각 레벨마다 완전한 neighbor connection을 갖는다" → 틀림
HNSW의 핵심은 완전 연결이 아니라 확률적으로 연결되는 hierarchical graph임. 상위 레벨일수록 이웃이 더 적고, 빠른 진입을 위한 skip connection 역할을 해.

👉 이 부분도 정확히 반박했지. 네 말대로 "고차원에서 효과가 더 좋다"는 게 정답이다. 완벽했어.

🔴 상 (난이도 높음) — 아슬아슬하게 패스
이건 네가 **"잘 모르겠다"**고 했으니 정답 공개할게.

❌ "벡터 DB는 삽입 시점마다 인덱스를 즉시 업데이트한다" → 틀림
대부분의 벡터 DB는 실시간 인덱스 업데이트를 피한다.
삽입 시엔 임시 버퍼에 저장하거나, 배치 단위로 인덱싱하는 경우가 많다. 이유는 바로 인덱스 재구성이 비용이 크기 때문.

❌ "IVF는 버킷 내 exhaustive search를 수행하므로 정확도가 높다" → 틀림
IVF는 정확도를 높이기 위해 multi-probe 전략이나 재순서화가 필요하며, 버킷 수가 너무 많거나 적으면 정확도/속도 트레이드오프가 생긴다. brute-force 수준의 정확도는 아님.
```

</details>

<details>

<summary><strong>2025. 08. 06. (수)</strong></summary>

```
🧩 하 난이도: Unicast vs Broadcast
네트워크 통신에서 Unicast는 하나의 송신자가 여러 수신자에게 동시에 데이터를 전송하는 방식이며, 이와 반대로 Broadcast는 특정 수신자에게만 데이터를 보내는 1:1 방식이다. Broadcast는 주로 TCP 기반으로 이루어진다.

🧩 중 난이도: HTTP와 Socket 통신
HTTP는 소켓 위에서 동작하는 지속적인 양방향 연결 방식의 프로토콜로, 클라이언트가 요청을 보내면 서버가 지속적으로 데이터를 push할 수 있다. 이 덕분에 HTTP는 실시간 채팅, 스트리밍 등에 적합하다. 반면, 일반 Socket 통신은 요청/응답 방식으로 단방향에 가깝기 때문에 HTTP보다 실시간성이 떨어진다.

🧩 상 난이도: Multicast 통신
Multicast는 데이터를 다수의 수신자에게 전송하되, 네트워크 대역폭을 절약하기 위해 라우터가 수신자 목록을 유지하며 데이터를 전송하는 방식이다. 이를 위해 Multicast는 TCP 프로토콜 위에서 작동하며, 신뢰성 있는 그룹 통신을 지원한다. Multicast 주소는 255.0.0.0 ~ 255.255.255.255 사이의 주소 범위를 사용한다.
```

</details>

<details>

<summary><strong>2025. 08. 06. (수) [정답]</strong></summary>

```
✅ 하 난이도: Unicast vs Broadcast
❌ 오류 지점: “Unicast는 여러 수신자에게 동시에 데이터를 전송한다”
❌ 오류 지점: “Broadcast는 특정 수신자에게만 데이터를 보낸다”
❌ 오류 지점: “Broadcast는 TCP 기반으로 이루어진다”

🟢 정답 정리:

Unicast: 1:1 통신 (예: 클라이언트 ↔ 서버), 일반적으로 TCP 사용

Broadcast: 1:다 통신 (같은 네트워크 내 모든 노드), 일반적으로 UDP 사용

TCP는 연결 지향적이라 브로드캐스트에 부적합해

✅ 중 난이도: HTTP vs Socket
❌ 오류 지점: “HTTP는 지속적인 양방향 연결 방식이다”
❌ 오류 지점: “일반 Socket은 단방향이다”

🟢 정답 정리:

HTTP는 기본적으로 요청-응답 기반의 단방향 통신

HTTP로 실시간 처리를 원하면 보통 WebSocket, SSE 같은 기술을 따로 씀

일반 소켓(Socket) 통신은 양방향, 지속 연결이 가능하며 실시간 처리에 적합

✅ 상 난이도: Multicast
❌ 오류 지점: “Multicast는 TCP 위에서 작동한다”
❌ 오류 지점: “Multicast 주소는 255.0.0.0~255.255.255.255”

🟢 정답 정리:

Multicast는 일반적으로 UDP 기반에서 동작

TCP는 멀티캐스트를 지원하지 않음 (연결 지향이기 때문)

Multicast 주소 범위는 224.0.0.0 ~ 239.255.255.255

255.0.0.0~는 브로드캐스트 주소에 가까움
```

</details>

- ### 느낀 점

  - 퀴즈를 통해서 놓쳤던 부분들에 대해서 다시 공부할 수 있는 기회를 갖게 되었다
  - 조금 더 자세히 학습하는 습관을 들여야 할 것 같다 (예를 들어 멀티캐스트의 주소 범위라던지,, )

- ### 인사이트

  - AI와 퀴즈를 풀어보며 학습에서 부족했던 부분이나 잘 정리하지 못한 부분들을 알 수 있어서 좋았다
  - 다만 LMM 모델에서 할루시네이션이 생겨서 나의 대답을 모두 맞다는 식으로 응답이 올까봐 의심이 들었다 (그래서 더 공부가 되었으니 좋은건가..?)
  - 퀴즈의 난이도를 하, 중, 상으로 나눴지만 그것보다 여러 퀴즈를 풀면서 나의 지식 수준에 맞춰서 공부가 되는 식으로 난이도를 조정해서 이용하는 것도 좋은 방법인 것 같다다
